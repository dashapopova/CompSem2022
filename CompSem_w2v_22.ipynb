{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "CompSem_w2v_22.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Векторные модели. Word2Vec\n",
        "\n",
        "+ Firth (1957:11):\n",
        "You shall know a word by the company it keeps . . .\n",
        "\n",
        "+ Дистрибутивная гипотеза: значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. \n",
        "\n",
        "+ Область лингвистики, которая занимается вычислением степени семантической близости между словами/текстами и т.п. на основании их распределения (дистрибуции) в больших массивах данных (текстовых корпусах) назвается **дистрибутивной семантикой**."
      ],
      "metadata": {
        "id": "NdJYiJAUVEHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кратко о существующих системах\n",
        "\n",
        "**GloVe**\n",
        "\n",
        "GloVe берет и строит полную матрицу совместной встречаемости и после этого с помощью алгоритмов уменьшения размерности преобразует ее так, чтобы вектора были опредленной длины\n",
        "\n",
        "\n",
        "**Word2Vec**\n",
        "\n",
        "Это уже нейросеть и она на основе корпуса постепенно подбирает коэффициенты (значения в векторах) для каждого слова так, чтобы с помощью них можно было наилучшим образом предсказывать слова по контексту\n",
        "\n",
        "**FastText**\n",
        "\n",
        "Если мы берем конкретные слова, мы не можем ничего сказать о тех, что нам не встретились (например, уже видели вагон и строитель, а вот вагоностроителя у нас не было). Если мы возьмем слова не целиком, а в виде будквенных нграмм, то мы сможем сложить неизвестные слова.\n",
        "\n",
        "**AdaGram**\n",
        "\n",
        "Все предыдущие модели основаны на графических оболочках и не учитывают многозначность и омонимию. Есть только один вектор для слова \"ключ\" и мы ничего с этим не можем сделать. AdaGram исходит из предположения, что у слова есть n вариантов и если они действительно отличаются и достаточно часто встречаются, он умеет их разделить.\n",
        "\n",
        "**BERT и ELMo**\n",
        "\n",
        "Эти модели не просто могут отличить значения слов, но и скорректировать их вектора в зависимости от контекста, например, понять, что в отрывках “чистый ключ в лесной чаще” и “ключ от квартиры” совсем разные “ключи”. https://habr.com/ru/post/487358/"
      ],
      "metadata": {
        "id": "aTBd1rztVEHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec"
      ],
      "metadata": {
        "id": "9mMfbQjeVEHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Одной из самых известных моделей для работы с дистрибутивной семантикой является word2vec. Технология основана на нейронной сети, предсказывающей вероятность встретить слово в заданном контексте. Этот инструмент был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов. Вот две самые главные статьи:\n",
        "\n",
        "+ [Efficient Estimation of Word Representations inVector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "+ [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n",
        "\n",
        "Полученные таким образом вектора называются распределенными представлениями слов, или **эмбеддингами**."
      ],
      "metadata": {
        "id": "iGjcLmigVEHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как это обучается?\n",
        "\n",
        "Мы задаём вектор для каждого слова с помощью матрицы $w$ и вектор контекста с помощью матрицы $W$. По сути, word2vec является обобщающим названием для двух архитектур Skip-Gram и Continuous Bag-Of-Words (CBOW).\n",
        "\n",
        "+ **CBOW** предсказывает текущее слово, исходя из окружающего его контекста.\n",
        "\n",
        "+ **Skip-gram**, наоборот, использует текущее слово, чтобы предугадывать окружающие его слова.\n",
        "  \n",
        "\n",
        "![cbow_skip-gram](./cbow_skip-gram.png)\n",
        "\n",
        "\n",
        "#### Как это работает?\n",
        "\n",
        "Word2vec принимает большой текстовый корпус в качестве входных данных и сопоставляет каждому слову вектор, выдавая координаты слов на выходе. Сначала он создает словарь, «обучаясь» на входных текстовых данных, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, согласно дистрибутивной гипотезе, имеющие схожий смысл), в векторном представлении будут иметь близкие координаты векторов-слов. Для вычисления близости слов используется косинусное расстояние между их векторами.\n",
        "\n",
        "С помощью дистрибутивных векторных моделей можно строить семантические пропорции (они же аналогии) и решать примеры:\n",
        "\n",
        "+ король: мужчина = королева: женщина $\\Rightarrow$\n",
        "+ король - мужчина + женщина = королева\n",
        "\n",
        "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)\n",
        "\n",
        "Ещё про механику с картинками [тут](https://habr.com/ru/post/446530/)\n",
        "\n",
        "#### Зачем это нужно?\n",
        "\n",
        "+ используется для решения семантических задач\n",
        "+ давайте подумаем, для описания каких семантических классов слов дистрибутивная информация особенно важна?\n",
        "+ несколько интересных статей по дистрибутивной семантике:\n",
        "\n",
        "* [Turney and Pantel 2010](https://jair.org/index.php/jair/article/view/10640)\n",
        "* [Lenci 2018](https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125254?journalCode=linguistics)\n",
        "* [Smith 2019](https://arxiv.org/pdf/1902.06006.pdf)\n",
        "* [Pennington et al. 2014](https://www.aclweb.org/anthology/D14-1162/)\n",
        "* [Faruqui et al. 2015](https://www.aclweb.org/anthology/N15-1184/)\n",
        "\n",
        "+ подаётся на вход нейронным сетям\n",
        "+ используется в Siri, Google Assistant, Alexa, Google Translate...\n",
        "\n",
        "#### Gensim\n",
        "\n",
        "Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот ее [документация](https://radimrehurek.com/gensim/models/word2vec.html).\n",
        "\n",
        "Если gensim у вас не стоит, то ставим: `pip install gensim`. \n",
        "\n",
        "`Gensim` регулярно обновляется, так что не будет лишним удостовериться, что у вас установлена последняя версия, а при необходимости проапдейтить библиотеку:\n",
        "\n",
        "`pip install gensim --upgrade`\n",
        "\n",
        "или\n",
        "\n",
        "`pip install gensim -U`\n",
        "\n",
        "Поскольку обучение и загрузка моделей могут занимать продолжительное время, иногда бывает полезно вести лог событий. Для этого используется стандартная питоновская библиотека `logging`.\n"
      ],
      "metadata": {
        "id": "iXS3fmb3VEHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import sys\n",
        "import gensim, logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ez-sfIRwVEHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем библиотеки Word2Vec\n",
        "from gensim.models.word2vec import Word2Vec # Собственно модель.\n",
        "from gensim.models import KeyedVectors # Семантические вектора.\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QXU0KrWbVFL0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как обучить свою модель\n",
        "\n",
        "NB! Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели."
      ],
      "metadata": {
        "id": "KkeVx8z_VEHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем модель. Основные параметры:\n",
        "\n",
        "+ данные должны быть итерируемым объектом\n",
        "+ vector_size — размер вектора,\n",
        "+ window — размер окна наблюдения,\n",
        "+ min_count — мин. частотность слова в корпусе,\n",
        "+ workers — количество ядер вашего процессора, чтоб запустить обучение в несколько потоков."
      ],
      "metadata": {
        "id": "y9sWIvd_VEIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "model.save(\"word2vec.model\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX58h0GsQmK7",
        "outputId": "0c2f4228-f7d7-42a8-d53b-9b7baa7a200b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-28 15:29:50,761 : INFO : collecting all words and their counts\n",
            "2022-01-28 15:29:50,763 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-01-28 15:29:50,770 : INFO : collected 12 word types from a corpus of 29 raw words and 9 sentences\n",
            "2022-01-28 15:29:50,771 : INFO : Creating a fresh vocabulary\n",
            "2022-01-28 15:29:50,773 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 12 unique words (100.0%% of original 12, drops 0)', 'datetime': '2022-01-28T15:29:50.772989', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-01-28 15:29:50,773 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 29 word corpus (100.0%% of original 29, drops 0)', 'datetime': '2022-01-28T15:29:50.773732', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-01-28 15:29:50,779 : INFO : deleting the raw counts dictionary of 12 items\n",
            "2022-01-28 15:29:50,780 : INFO : sample=0.001 downsamples 12 most-common words\n",
            "2022-01-28 15:29:50,781 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3.5001157321504532 word corpus (12.1%% of prior 29)', 'datetime': '2022-01-28T15:29:50.781835', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-01-28 15:29:50,784 : INFO : estimated required memory for 12 words and 100 dimensions: 15600 bytes\n",
            "2022-01-28 15:29:50,788 : INFO : resetting layer weights\n",
            "2022-01-28 15:29:50,790 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-01-28T15:29:50.790108', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'build_vocab'}\n",
            "2022-01-28 15:29:50,791 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 12 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-01-28T15:29:50.791922', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-01-28 15:29:50,804 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-28 15:29:50,804 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-28 15:29:50,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-28 15:29:50,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-28 15:29:50,808 : INFO : EPOCH - 1 : training on 29 raw words (3 effective words) took 0.0s, 622 effective words/s\n",
            "2022-01-28 15:29:50,816 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-28 15:29:50,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-28 15:29:50,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-28 15:29:50,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-28 15:29:50,828 : INFO : EPOCH - 2 : training on 29 raw words (3 effective words) took 0.0s, 244 effective words/s\n",
            "2022-01-28 15:29:50,833 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-28 15:29:50,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-28 15:29:50,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-28 15:29:50,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-28 15:29:50,838 : INFO : EPOCH - 3 : training on 29 raw words (1 effective words) took 0.0s, 162 effective words/s\n",
            "2022-01-28 15:29:50,846 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-28 15:29:50,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-28 15:29:50,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-28 15:29:50,852 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-28 15:29:50,853 : INFO : EPOCH - 4 : training on 29 raw words (4 effective words) took 0.0s, 418 effective words/s\n",
            "2022-01-28 15:29:50,858 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-28 15:29:50,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-28 15:29:50,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-28 15:29:50,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-28 15:29:50,865 : INFO : EPOCH - 5 : training on 29 raw words (6 effective words) took 0.0s, 762 effective words/s\n",
            "2022-01-28 15:29:50,867 : INFO : Word2Vec lifecycle event {'msg': 'training on 145 raw words (17 effective words) took 0.1s, 229 effective words/s', 'datetime': '2022-01-28T15:29:50.867682', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-01-28 15:29:50,868 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=12, vector_size=100, alpha=0.025)', 'datetime': '2022-01-28T15:29:50.868954', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n",
            "2022-01-28 15:29:50,870 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-01-28T15:29:50.870411', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'saving'}\n",
            "2022-01-28 15:29:50,872 : INFO : not storing attribute cum_table\n",
            "2022-01-28 15:29:50,874 : INFO : saved word2vec.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Финализируем нашу модель. Ее нельзя будет доучить теперь, но она начнет занимать гораздо меньше места\n",
        "model.init_sims(replace=True)"
      ],
      "metadata": {
        "id": "3mJs8u0cVehr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.wv['graph']  # get numpy vector of a word\n",
        "\n",
        "print(vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE4u0h5vQ-C0",
        "outputId": "075fbde3-5654-4824-ac16-bb6311973afa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.14864719  0.06321594  0.08949995  0.09902015  0.12876756 -0.10636206\n",
            "  0.01906639  0.10428586 -0.04897691 -0.10646288]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('human')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc4zTR6UVIUR",
        "outputId": "26c843c1-f6df-4311-d392-ed77e9d75b2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('trees', 0.17272794246673584),\n",
              " ('eps', 0.16694682836532593),\n",
              " ('response', 0.11118265986442566),\n",
              " ('interface', 0.10940766334533691),\n",
              " ('system', 0.07963485270738602),\n",
              " ('user', 0.04130299761891365),\n",
              " ('survey', 0.0377129502594471),\n",
              " ('graph', 0.00831594318151474),\n",
              " ('minors', -0.0058967843651771545),\n",
              " ('computer', -0.0742427185177803)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match(['human', 'computer', 'user'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lNrrB5Q_V0pf",
        "outputId": "759f89c3-5a57-4620-8cf5-bcb0e2cd46cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'computer'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['user'], negative=['human'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVLVHrmbWI2P",
        "outputId": "4cab6d44-6521-4254-a78d-d335e0dfffbc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('time', 0.0905691534280777),\n",
              " ('graph', 0.04305828735232353),\n",
              " ('survey', 0.026922456920146942),\n",
              " ('eps', -0.025620516389608383),\n",
              " ('minors', -0.02801719680428505),\n",
              " ('computer', -0.06851557642221451),\n",
              " ('interface', -0.06950870156288147),\n",
              " ('response', -0.09015342593193054),\n",
              " ('trees', -0.13451507687568665),\n",
              " ('system', -0.13811412453651428)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity('user','computer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQUZx0WmW88W",
        "outputId": "d92155b1-4b58-44a7-8c73-6ced0f537431"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.16911626"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Параметры варьирования\n",
        "\n",
        "1) препроцессинг -- лемматизировать или нет, например, вдруг мы хотим посмотреть на морфологические пропорции? тогда лемматизировать не нужно\n",
        "\n",
        "2) размер корпуса -- чем больше, тем лучше, но! не для семантических задач -- для них важнее качество\n",
        "\n",
        "3) размер словаря\n",
        "\n",
        "4) negative samples\n",
        "\n",
        "5) количество итераций\n",
        "\n",
        "6) длина вектора -- 100-300 (судя по всему, >300 не сильно улучшает результаты)\n",
        "\n",
        "7) длина окна -- для синтаксических задач, примерно 4, для семантических задач, большое окно, 8, 10.\n",
        "\n",
        "Хорошая статья про сравнение моделей с варьированием параметров: https://www.aclweb.org/anthology/D14-1162.pdf"
      ],
      "metadata": {
        "id": "EZl_fECYVEIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как использовать готовую модель\n",
        "\n",
        "#### RusVectōrēs\n",
        "\n",
        "На сайте RusVectōrēs (https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятора семантической близости».\n",
        "\n",
        "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)"
      ],
      "metadata": {
        "id": "vPsDlgqQVEIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Работа с моделью\n",
        "\n",
        "Существуют несколько форматов, в которых могут храниться модели. Во-первых, данные могут храниться в нативном формате word2vec, при этом модель может быть бинарной или не бинарной. Для загрузки модели в формате word2vec в классе `KeyedVectors` (в котором хранится большинство относящихся к дистрибутивным моделям функций) существует функция `load_word2vec_format`, а бинарность модели можно указать в аргументе `binary` (внизу будет пример). Помимо этого, модель можно хранить и в собственном формате gensim, для этого существует класс `Word2Vec` с функцией `load`. Поскольку модели бывают разных форматов, то для них написаны разные функции загрузки; бывает полезно учитывать это в своем скрипте. Наш код определяет тип модели по её расширению, но вообще файл с моделью может называться как угодно, жестких ограничений для расширения нет.\n",
        "\n",
        "Для новых моделей перешли на загрузку с использованием инфраструктуры Nordic Language Processing Laboratory. На практике это означает, что теперь по клику на модель вы скачиваете zip-архив с уникальным числовым идентификатором (например, `220.zip`). Внутри архива всегда находится файл `meta.json`, содержащий в структурированном и стандартном виде информацию о модели и корпусе, на котором она обучена. word2vec-модели лежат в архивах сразу в двух word2vec-форматах: бинарном `model.bin` (удобен для быстрой загрузки) и текстовом `model.txt` (удобен для просмотра человеком). Давайте скачаем [новейшую модель для русского языка](http://vectors.nlpl.eu/repository/20/220.zip) и загрузим в её в память. Распаковывать скачанный архив для обычных моделей не нужно, так как его содержимое прочитается при помощи специальной инструкции:"
      ],
      "metadata": {
        "id": "v290agZHVEIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import wget\n",
        "\n",
        "model_url = 'http://vectors.nlpl.eu/repository/20/220.zip'\n",
        "m = wget.download(model_url)\n",
        "model_file = model_url.split('/')[-1]\n",
        "with zipfile.ZipFile(model_file, 'r') as archive:\n",
        "    stream = archive.open('model.bin')\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odgo87YiEh93",
        "outputId": "0559aaad-5e86-42ba-8993-36297fe6dbdd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-28 15:49:56,280 : INFO : loading projection weights from <zipfile.ZipExtFile name='model.bin' mode='r' compress_type=deflate>\n",
            "2022-01-28 15:50:01,494 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (249333, 300) matrix of type float32 from <zipfile.ZipExtFile [closed]>', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-01-28T15:50:01.494571', 'gensim': '4.1.2', 'python': '3.7.12 (default, Sep 10 2021, 00:21:48) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'load_word2vec_format'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Мини-исследование**: Давайте протестируем, выделяет ли модель функцию интенсификации в прилагательных? Например, *ужасный курильщик* может интерпретироваться как *человек, который много курит*, а не только как (не столько как) *очень плохой человек-курильщик*. Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
      ],
      "metadata": {
        "id": "w3UV2ZV4VEIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "words = ['хороший_ADJ', 'плохой_ADJ', 'ужасный_ADJ','жуткий_ADJ', 'страшный_ADJ', 'красный_ADJ', 'синий_ADJ']"
      ],
      "outputs": [],
      "metadata": {
        "id": "_KWmL5JSVEIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). NB! В названиях моделей на `rusvectores` указано, какой тегсет они используют (mystem, upos и т.д.)\n",
        "\n",
        "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:\n"
      ],
      "metadata": {
        "id": "YxKyzxJ_VEIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "for word in words:\n",
        "    # есть ли слово в модели? \n",
        "    if word in model:\n",
        "        print(word)\n",
        "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
        "        print(model[word][:10])\n",
        "        # выдаем 10 ближайших соседей слова:\n",
        "        for i in model.most_similar(positive=[word], topn=10):\n",
        "            # слово + коэффициент косинусной близости\n",
        "            print(i[0], i[1])\n",
        "        print('\\n')\n",
        "    else:\n",
        "        # Увы!\n",
        "        print('Увы, слова \"%s\" нет в модели!' % word)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_ADJ\n",
            "[-0.5533533   3.525192    1.3954544   0.50957227  0.9530872   0.42150345\n",
            "  0.14798506 -0.89938575 -1.9526412  -2.9605858 ]\n",
            "плохой_ADJ 0.7704135179519653\n",
            "отличный_ADJ 0.745093822479248\n",
            "хороший_ADV 0.7096987962722778\n",
            "неплохой_ADJ 0.7080509662628174\n",
            "хорошо_ADJ 0.685799777507782\n",
            "превосходный_ADJ 0.66509610414505\n",
            "приятный_ADJ 0.6305955052375793\n",
            "хорошо_ADV 0.6236262321472168\n",
            "дурной_ADJ 0.5771215558052063\n",
            "нужный_ADJ 0.5764609575271606\n",
            "\n",
            "\n",
            "плохой_ADJ\n",
            "[ 1.47815     3.4967737   0.6200617   0.21216297 -2.1780734  -0.71112794\n",
            " -0.55119324 -0.8843036  -1.0574621  -2.4701962 ]\n",
            "хороший_ADJ 0.7704134583473206\n",
            "плохой_ADV 0.6875114440917969\n",
            "дурной_ADJ 0.6704886555671692\n",
            "плохо_ADJ 0.6194170117378235\n",
            "скверный_ADJ 0.6098257303237915\n",
            "слабый_ADJ 0.5972127914428711\n",
            "хороший_ADV 0.5740218162536621\n",
            "плохо_ADV 0.5671497583389282\n",
            "неплохой_ADJ 0.5508592128753662\n",
            "неудовлетворительный_ADJ 0.5305141806602478\n",
            "\n",
            "\n",
            "ужасный_ADJ\n",
            "[-0.7115563   0.14254573 -0.9630084  -0.7578321  -0.35663527 -2.2121139\n",
            " -1.0280207   1.6492867   0.29676497 -1.4163486 ]\n",
            "страшный_ADJ 0.8240757584571838\n",
            "жуткий_ADJ 0.7339372038841248\n",
            "ужасать_VERB 0.7301003932952881\n",
            "отвратительный_ADJ 0.7261567115783691\n",
            "чудовищный_ADJ 0.7105397582054138\n",
            "жестокий_ADJ 0.6685523986816406\n",
            "кошмарный_ADJ 0.6566017866134644\n",
            "печальный_ADJ 0.6309635639190674\n",
            "ужас_NOUN 0.6154152750968933\n",
            "невыносимый_ADJ 0.6138052940368652\n",
            "\n",
            "\n",
            "жуткий_ADJ\n",
            "[-2.6076715  -0.55262923  0.40085354  0.53245926 -0.627791   -1.1019641\n",
            " -0.9849679   1.96757     0.7459387  -1.8215437 ]\n",
            "страшный_ADJ 0.7592697143554688\n",
            "ужасный_ADJ 0.7339370846748352\n",
            "зловещий_ADJ 0.7206223607063293\n",
            "жутковатый_ADJ 0.7082728147506714\n",
            "мрачный_ADJ 0.7029562592506409\n",
            "кошмарный_ADJ 0.670348048210144\n",
            "жуть_NOUN 0.6547104716300964\n",
            "странный_ADJ 0.6514071226119995\n",
            "отвратительный_ADJ 0.6419169306755066\n",
            "ужасать_VERB 0.6389007568359375\n",
            "\n",
            "\n",
            "страшный_ADJ\n",
            "[-2.2825887  -1.2624556   1.1256089  -0.6564649  -0.09272972 -2.5593076\n",
            " -1.475779    2.8121662   0.97330487 -1.0684136 ]\n",
            "ужасный_ADJ 0.8240758180618286\n",
            "жуткий_ADJ 0.759269654750824\n",
            "чудовищный_ADJ 0.6618976593017578\n",
            "ужасать_VERB 0.6316395998001099\n",
            "ужас_NOUN 0.6198166012763977\n",
            "жестокий_ADJ 0.614973783493042\n",
            "зловещий_ADJ 0.6030802726745605\n",
            "кровавый_ADJ 0.5815890431404114\n",
            "мрачный_ADJ 0.5714954137802124\n",
            "страшилище_NOUN 0.5660818815231323\n",
            "\n",
            "\n",
            "красный_ADJ\n",
            "[ 1.8484586  -2.8723414  -0.46619502 -2.2685125  -2.5031633  -1.0955416\n",
            " -0.6339649   2.7543478   0.505872    0.05006269]\n",
            "*красный_ADJ 0.5675032734870911\n",
            "крайовый_ADJ 0.5446105003356934\n",
            "малиновый_ADJ 0.5436140298843384\n",
            "алый_ADJ 0.5398156046867371\n",
            "белый_ADJ 0.5338898301124573\n",
            "красный_NOUN 0.5177537798881531\n",
            "людова_PROPN 0.5174776315689087\n",
            "красный_PROPN 0.513830304145813\n",
            "малиновой_ADJ 0.49443739652633667\n",
            "черный_ADJ 0.4935334026813507\n",
            "\n",
            "\n",
            "синий_ADJ\n",
            "[ 2.3165712  -2.4371688  -1.9381734   0.4337334  -0.40584928 -0.42849195\n",
            " -0.5164158   2.7145562  -0.58174306 -0.03131035]\n",
            "голубой_ADJ 0.879791796207428\n",
            "желтый_ADJ 0.82841557264328\n",
            "синий_NOUN 0.825542151927948\n",
            "зеленый_ADJ 0.7674750089645386\n",
            "фиолетовый_ADJ 0.7418162822723389\n",
            "оранжевый_ADJ 0.7393277287483215\n",
            "серый_ADJ 0.734974205493927\n",
            "розовый_ADJ 0.7345995306968689\n",
            "жёлтый_ADJ 0.7321051955223083\n",
            "лиловый_ADJ 0.7305857539176941\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiZ2jQHEVEIu",
        "outputId": "3f255647-36d7-423b-ebda-64dd039a0f20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Находим косинусную близость пары слов:"
      ],
      "metadata": {
        "id": "2Mdpu0ztVEIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "print(model.similarity('плохой_ADJ', 'хороший_ADJ'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7704135\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37gfNT_-VEIw",
        "outputId": "6fdcba41-ed9e-49f7-ddba-6eccad66bf5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "print(model.similarity('плохой_ADJ', 'синий_ADJ'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.027845463\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF1gSK93VEIy",
        "outputId": "df9c105a-489e-421c-b067-27293c64ae09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "print(model.similarity('плохой_ADJ', 'страшный_ADJ'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3176287\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b73fea-2ef8-448c-a585-18cedd556568",
        "id": "yQAZ_fnrY7O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "print(model.similarity('ужасный_ADJ', 'жуткий_ADJ'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.73393726\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdIxSXfpVEIz",
        "outputId": "93044413-309c-4039-d9d9-4aacf1cc530b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем составить пропорцию:\n",
        "\n",
        "+ positive — вектора, которые мы складываем\n",
        "+ negative — вектора, которые вычитаем"
      ],
      "metadata": {
        "id": "IN24380IVEI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "print(model.most_similar(positive=['плохой_ADJ', 'ужасный_ADJ'], negative=['хороший_ADJ'])[0][0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "страшный_ADJ\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8WiWZpVEI1",
        "outputId": "7882167e-bd2f-474e-b3f0-a40c8385516d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найди лишнее!"
      ],
      "metadata": {
        "id": "F5VLNFUhVEI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "print(model.doesnt_match('плохой_ADJ хороший_ADJ ужасный_ADJ страшный_ADJ'.split()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_ADJ\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Eqd1B2VEI4",
        "outputId": "d0e3c3b4-8e3c-4961-e4d2-4df669373298"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "print(model.doesnt_match('плохой_ADJ ужасный_ADJ страшный_ADJ'.split()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "плохой_ADJ\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da5fov1DVEI5",
        "outputId": "ecda17d8-3847-4973-d49b-fb43274a4f79"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "for word, score in model.most_similar(positive=['ужасно_ADV'], negative=['плохой_ADJ']):\n",
        "    print(f'{score:.2}\\t{word}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.56\tстрашно_ADV\n",
            "0.49\tбезумно_ADV\n",
            "0.45\tнесказанно_ADV\n",
            "0.43\tбезмерно_ADV\n",
            "0.43\tнеимоверно_ADV\n",
            "0.4\tдонельзя_ADV\n",
            "0.4\tнеобыкновенно_ADV\n",
            "0.39\tчрезвычайный_ADV\n",
            "0.39\tчрезвычайность_NOUN\n",
            "0.38\tжутко_ADV\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJndzvCqVEI6",
        "outputId": "183ee3fb-cdc7-4ef6-c064-a045700c6015"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что означают полученные результаты для нашего исследования? Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
      ],
      "metadata": {
        "id": "-R0i47cLVEI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация\n",
        "\n",
        "Можно использовать разные методы того, как преобразовать векторы так, чтобы можно было их поместить на двумерное пространство, например, с помощью PCA. В зависимости от того, относительно какого набора слов вы пытаетесь найти оптимально отображение на двумерное пространство, у вас могут получаться разные результаты"
      ],
      "metadata": {
        "id": "PjRcz2nrVEI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "DTpnk9BsVEI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "words = ['хороший_ADJ', 'плохой_ADJ', 'ужасный_ADJ','жуткий_ADJ', 'страшный_ADJ', 'красный_ADJ', 'синий_ADJ']\n",
        "X = model[words]#model.wv[words]"
      ],
      "outputs": [],
      "metadata": {
        "id": "GVk5tY3WVEI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "pca = PCA(n_components=2)\n",
        "coords = pca.fit_transform(X)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QHCQntR-VEI_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
        "plt.title('Words')\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hVia6FDvVEJD",
        "outputId": "6864b9d0-9855-4f7a-d54e-48cb433049b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Оценка\n",
        "\n",
        "Существуют специальные датасеты для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии, а второй используется для оценки коэффициента семантической близости.\n",
        "\n",
        "#### Word Similarity\n",
        "\n",
        "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n",
        "\n",
        "| слово 1    | слово 2    | близость |\n",
        "|------------|------------|----------|\n",
        "| кошка      | собака     | 0.7      | \n",
        "| чашка      | кружка     | 0.9      | \n",
        "\n",
        "Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния о слова.\n",
        "\n",
        "#### Аналогии\n",
        "\n",
        "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
        "\n",
        "В качестве слов-модификатор мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Датасет будет выглядеть следующм образом:\n",
        "\n",
        "| слово 1    | слово 2    | отношение     | \n",
        "|------------|------------|---------------|\n",
        "| Россия     | Москва     | страна-столица| \n",
        "| Норвегия   | Осло       | страна-столица|\n",
        "\n",
        "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой.\n",
        "\n",
        "[Датасеты для русского языка](https://rusvectores.org/static/testsets/) можно скачать на странице с моделями на RusVectores."
      ],
      "metadata": {
        "id": "TAJ4CiDDVEJJ"
      }
    }
  ]
}